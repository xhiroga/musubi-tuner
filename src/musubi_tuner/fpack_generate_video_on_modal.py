"""
FramePack I2V Video Generation on Modal with Advanced Profiling

This script provides Modal Functions for running FramePack I2V video generation in the cloud
with comprehensive profiling capabilities based on Modal's torch_profiling example.

Profiling Features:
- PyTorch Profiler with CPU and CUDA activity tracking
- Memory profiling and shape recording
- Stack trace recording for debugging
- TensorBoard trace generation
- Timing logs and performance metrics
- Local and remote profiling result management

Usage:
1. Setup models:
   modal run src/musubi_tuner/fpack_generate_video_on_modal.py::upload_models_from_local --local-model-dir /path/to/models
   
2. Test setup:
   modal run src/musubi_tuner/fpack_generate_video_on_modal.py::test_modal_setup
   
3. Generate video with profiling:
   modal run src/musubi_tuner/fpack_generate_video_on_modal.py::profile_video_generation \
       --image-path /path/to/image.jpg --prompt "rotating 360 degrees" \
       --profile-steps 3 --record-shapes --profile-memory
   
   Or use the Makefile:
   make fpack_generate_video_on_modal IMAGE_PATH=/path/to/image.jpg SAVE_PATH=/path/to/output

4. Download profiling results:
   modal run src/musubi_tuner/fpack_generate_video_on_modal.py::download_profiling_results \
       --local-output-dir ./profiling_results

5. List models:
   modal run src/musubi_tuner/fpack_generate_video_on_modal.py::list_models

6. Serve TensorBoard (experimental):
   modal deploy src/musubi_tuner/fpack_generate_video_on_modal.py

Requirements:
- Modal account and CLI setup
- Model files (either uploaded or downloaded from HF Hub)
- Input image for video generation

Environment Variables:
- HF_TOKEN: Hugging Face token (if downloading models from private repos)
"""

import modal
import os
from pathlib import Path
from typing import Optional, Dict, Any
from uuid import uuid4

# CUDAç’°å¢ƒã®è¨­å®š
cuda_version = "12.8.0"
flavor = "devel"  # includes full CUDA toolkit
operating_sys = "ubuntu22.04"
tag = f"{cuda_version}-{flavor}-{operating_sys}"

# Modalç”¨ã®ã‚¤ãƒ¡ãƒ¼ã‚¸ã‚’æ§‹ç¯‰
ml_image = (
    modal.Image.from_registry(f"nvidia/cuda:{tag}", add_python="3.11")
    .apt_install("git", "ffmpeg", "libgl1", "libglib2.0-0", "libsm6", "libxrender1", "libxext6")
    .pip_install("uv")
    .run_commands([
        # fpack_generate_video.pyã®å…¨ä¾å­˜é–¢ä¿‚ã‚’uvã§é«˜é€Ÿã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
        """uv pip install --system --compile-bytecode \
           'torch>=2.7.1' \
           'torchvision>=0.22.1' \
           torchaudio \
           'transformers>=4.46.3' \
           'diffusers>=0.32.1' \
           'safetensors>=0.4.5' \
           'pillow>=10.2.0' \
           'numpy<2' \
           'tqdm>=4.66.5' \
           'accelerate>=1.6.0' \
           'diskcache>=5.6.3' \
           'huggingface_hub[hf_transfer]>=0.30.0' \
           'opencv-python>=4.10.0.84' \
           psutil \
           'einops>=0.7.0' \
           packaging \
           requests \
           'av==14.0.1' \
           'bitsandbytes>=0.45.0' \
           'sageattention>=1.0.6' \
           'toml>=0.10.2' \
           'voluptuous>=0.15.2' \
           'modal>=1.0.3' \
           'ftfy==6.3.1' \
           'easydict==1.13' \
           argparse \
           logging \
           datetime"""
    ])
    .env({
        "HF_HUB_ENABLE_HF_TRANSFER": "1",
        "CUDA_VISIBLE_DEVICES": "0"
    })
    .add_local_python_source("musubi_tuner")  # ãƒ­ãƒ¼ã‚«ãƒ«ã®musubi_tunerãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’è¿½åŠ 
)

app = modal.App("fpack-generate-video-on-modal")
model_volume = modal.Volume.from_name("fpack-generate-video-on-modal-models", create_if_missing=True)
# ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°çµæœç”¨ã®Volume
profiling_volume = modal.Volume.from_name("fpack-generate-video-profiling", create_if_missing=True)

PROFILING_DIR = Path("/profiling")

@app.function(
    image=ml_image,
    gpu="H100",  # é«˜æ€§èƒ½GPU
    volumes={
        "/models": model_volume,
        PROFILING_DIR: profiling_volume
    },
    timeout=3600,  # 1æ™‚é–“ã®ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ
    memory=32768,  # 32GB RAM
)
def profile_video_generation(
    image_bytes: bytes,
    image_filename: str,
    prompt: str = "rotating 360 degrees",
    video_size: tuple = (960, 544),
    fps: int = 30,
    infer_steps: int = 10,
    video_sections: int = 1,
    latent_window_size: int = 5,
    seed: int = 1234,
    save_path: str = "/tmp/output",
    # ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°è¨­å®š
    profile_steps: int = 3,
    profile_label: Optional[str] = None,
    record_shapes: bool = False,
    profile_memory: bool = True,
    with_stack: bool = True,
    print_profile_summary: int = 10
):
    """
    Modalä¸Šã§FramePackã«ã‚ˆã‚‹å‹•ç”»ç”Ÿæˆã‚’å®Ÿè¡Œã—ã€è©³ç´°ãªãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°ã‚’è¡Œã†é–¢æ•°
    Modalã®torch_profilingä¾‹ã«åŸºã¥ã„ã¦å®Ÿè£…
    """
    import sys
    import argparse
    import torch
    import json
    import time
    from datetime import datetime
    from pathlib import Path
    
    # musubi_tunerãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‹ã‚‰fpack_generate_videoã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
    from musubi_tuner.fpack_generate_video import get_generation_settings, generate, save_output
    
    # ä¸€æ„ã®ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°ã‚»ãƒƒã‚·ãƒ§ãƒ³IDã‚’ç”Ÿæˆ
    session_id = str(uuid4())
    timestamp = datetime.fromtimestamp(time.time()).strftime("%Y%m%d-%H%M%S")
    
    # ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°ç”¨ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ
    function_name = "fpack_video_generation"
    profile_label_suffix = f"_{profile_label}" if profile_label else ""
    profile_session_dir = PROFILING_DIR / f"{function_name}{profile_label_suffix}" / f"{timestamp}_{session_id}"
    profile_session_dir.mkdir(parents=True, exist_ok=True)
    
    print(f"ğŸ” Starting profiled video generation on Modal...")
    print(f"ğŸ“Š Profile session: {session_id}")
    print(f"ğŸ“ Profile directory: {profile_session_dir}")
    
    # ç”»åƒãƒã‚¤ãƒŠãƒªãƒ‡ãƒ¼ã‚¿ã‚’ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
    temp_dir = "/tmp/modal_input"
    os.makedirs(temp_dir, exist_ok=True)
    
    temp_image_path = os.path.join(temp_dir, image_filename)
    with open(temp_image_path, 'wb') as f:
        f.write(image_bytes)
    
    print(f"ğŸ–¼ï¸  Saved input image to: {temp_image_path}")
    print(f"ğŸ“ Image size: {len(image_bytes)} bytes")
    
    # Makefileã®å¼•æ•°ã‚’å†ç¾ã—ã¦argparse.Namespaceã‚’æ§‹ç¯‰
    args = argparse.Namespace()
    
    # ãƒ¢ãƒ‡ãƒ«ãƒ‘ã‚¹ï¼ˆVolumeå†…ã®æ­£ã—ã„æ§‹é€ ã«åŸºã¥ãï¼‰
    args.dit = "/models/models/diffusion_models/FramePackI2V_HY"
    args.vae = "/models/models/vae/diffusion_pytorch_model.safetensors"
    args.text_encoder1 = "/models/models/text_encoder/model-00001-of-00004.safetensors"
    args.text_encoder2 = "/models/models/text_encoder_2/model.safetensors"
    args.image_encoder = "/models/models/image_encoder/model.safetensors"
    
    # å…¥åŠ›ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
    args.image_path = temp_image_path
    args.prompt = prompt
    args.video_size = list(video_size)
    args.fps = fps
    args.infer_steps = infer_steps
    args.video_sections = video_sections
    args.latent_window_size = latent_window_size
    args.seed = seed
    args.save_path = save_path
    
    # ãƒ‡ãƒã‚¤ã‚¹ãƒ»æœ€é©åŒ–è¨­å®š
    args.device = "cuda"
    args.attn_mode = "sdpa"
    args.fp8 = False
    args.fp8_llm = False
    args.fp8_scaled = True
    
    # VAEè¨­å®š
    args.vae_chunk_size = 32
    args.vae_spatial_tile_sample_min_size = 128
    
    # ãã®ä»–ã®è¨­å®š
    args.cache_dir = "/tmp/.cache/musubi_tuner"
    args.optimized_model_dir = "/models/models/diffusion_models/optimized"
    args.log_level = "DEBUG"
    
    # ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°è¨­å®š
    args.profile = True
    args.profile_shapes = record_shapes
    args.profile_memory = profile_memory
    args.profile_stack = with_stack
    
    # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤
    args.negative_prompt = None
    args.custom_system_prompt = None
    args.video_seconds = 5.0
    args.one_frame_inference = None
    args.control_image_path = None
    args.control_image_mask_path = None
    args.end_image_path = None
    args.latent_paddings = None
    args.f1 = False
    args.rope_scaling_factor = 0.5
    args.rope_scaling_timestep_threshold = None
    args.lora_weight = None
    args.lora_multiplier = 1.0
    args.include_patterns = None
    args.exclude_patterns = None
    args.save_merged_model = None
    args.lycoris = False
    args.blocks_to_swap = 0
    args.output_type = "video"
    args.no_metadata = False
    args.latent_path = None
    args.bulk_decode = False
    args.sample_solver = "unipc"
    args.embedded_cfg_scale = 10.0
    args.guidance_scale = 1.0
    args.guidance_rescale = 0.0
    
    # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ
    os.makedirs(save_path, exist_ok=True)
    os.makedirs(args.cache_dir, exist_ok=True)
    
    try:
        # ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’è¨­å®š
        if profile_steps < 3:
            raise ValueError("Profile steps must be at least 3 when using default schedule")
        
        schedule = torch.profiler.schedule(
            wait=1,
            warmup=1, 
            active=profile_steps - 2,
            repeat=0
        )
        
        print(f"ğŸ¬ Starting profiled video generation...")
        print(f"ğŸ“Š Profile config: steps={profile_steps}, shapes={record_shapes}, memory={profile_memory}, stack={with_stack}")
        print(f"Input image: {temp_image_path}")
        print(f"Prompt: {prompt}")
        print(f"Video size: {video_size}")
        print(f"Output path: {save_path}")
        
        # ã‚¿ã‚¤ãƒŸãƒ³ã‚°ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ
        timing_log_path = profile_session_dir / "timing.log"
        start_time = time.time()
        
        def log_timing(message):
            elapsed = time.time() - start_time
            with open(timing_log_path, 'a') as f:
                f.write(f"[T+{elapsed:.2f}s] {message}\n")
            print(f"â±ï¸  [T+{elapsed:.2f}s] {message}")
        
        log_timing("Profile session started")
        
        # è©³ç´°ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°ã®å®Ÿè¡Œ
        activities = [torch.profiler.ProfilerActivity.CPU, torch.profiler.ProfilerActivity.CUDA]
        
        with torch.profiler.profile(
            activities=activities,
            schedule=schedule,
            on_trace_ready=torch.profiler.tensorboard_trace_handler(str(profile_session_dir)),
            record_shapes=record_shapes,
            profile_memory=profile_memory,
            with_stack=with_stack
        ) as prof:
            # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ 
            prof.add_metadata_json("args", json.dumps(vars(args), default=str))
            prof.add_metadata_json("session_info", json.dumps({
                "session_id": session_id,
                "timestamp": timestamp,
                "image_filename": image_filename,
                "prompt": prompt,
                "video_size": video_size,
                "profile_steps": profile_steps
            }))
            
            log_timing("Profiler initialized")
            
            for step in range(profile_steps):
                log_timing(f"Starting profile step {step + 1}/{profile_steps}")
                
                # ç”Ÿæˆè¨­å®šã‚’å–å¾—
                gen_settings = get_generation_settings(args)
                log_timing(f"Generation settings configured")
                
                # å‹•ç”»ç”Ÿæˆã‚’å®Ÿè¡Œ
                result = generate(args, gen_settings, prof=prof, log_timing=log_timing)
                
                if result is None:
                    # Model was saved, no further processing needed
                    log_timing("Model save completed, skipping video generation")
                    prof.step()
                    continue
                
                vae, latent = result
                
                # çµæœã‚’ä¿å­˜
                save_output(args, vae, latent[0], gen_settings.device, None, log_timing=log_timing)
                
                log_timing(f"Completed profile step {step + 1}/{profile_steps}")
                prof.step()
        
        # ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°çµæœã®ã‚µãƒãƒªãƒ¼ã‚’ç”Ÿæˆ
        if print_profile_summary > 0:
            print(f"\nğŸ“Š Profile Summary (Top {print_profile_summary} operations by CUDA time):")
            summary_table = prof.key_averages().table(
                sort_by="cuda_time_total", 
                row_limit=print_profile_summary
            )
            print(summary_table)
            
            # ã‚µãƒãƒªãƒ¼ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
            summary_path = profile_session_dir / "profile_summary.txt"
            with open(summary_path, 'w') as f:
                f.write(f"Profile Summary - {timestamp}\n")
                f.write(f"Session ID: {session_id}\n")
                f.write(f"Prompt: {prompt}\n")
                f.write(f"Video Size: {video_size}\n")
                f.write(f"Profile Steps: {profile_steps}\n")
                f.write("=" * 80 + "\n")
                f.write(summary_table)
        
        log_timing("Profile analysis completed")
        
        # ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°çµæœã®ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§ã‚’å–å¾—
        profile_files = []
        for file_path in profile_session_dir.rglob("*"):
            if file_path.is_file():
                relative_path = file_path.relative_to(PROFILING_DIR)
                profile_files.append(str(relative_path))
        
        # Volume ã«ã‚³ãƒŸãƒƒãƒˆ
        profiling_volume.commit()
        
        print(f"âœ… Profiled video generation completed successfully!")
        print(f"ğŸ“Š Profile results saved to Volume: {profile_session_dir}")
        print(f"ğŸ“ Profile files: {len(profile_files)} files")
        
        # ç”Ÿæˆã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç¢ºèªã—ã¦ãƒã‚¤ãƒŠãƒªãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦è¿”ã™
        output_files = list(Path(save_path).glob("*.mp4"))
        result_files = {}
        
        for file_path in output_files:
            if file_path.is_file():
                with open(file_path, 'rb') as f:
                    file_data = f.read()
                result_files[file_path.name] = file_data
                print(f"ğŸ“„ Captured output file: {file_path.name} ({len(file_data)} bytes)")
        
        log_timing("Process completed")
        
        return {
            "status": "success",
            "session_id": session_id,
            "output_path": save_path,
            "files": [str(f) for f in output_files],
            "result_files": result_files,  # ãƒã‚¤ãƒŠãƒªãƒ‡ãƒ¼ã‚¿ã‚’å«ã‚€
            "profile_session_dir": str(profile_session_dir.relative_to(PROFILING_DIR)),
            "profile_files": profile_files,
            "timing_log": timing_log_path.read_text() if timing_log_path.exists() else None
        }
        
    except Exception as e:
        print(f"âŒ Error during profiled video generation: {str(e)}")
        import traceback
        error_trace = traceback.format_exc()
        traceback.print_exc()
        
        # ã‚¨ãƒ©ãƒ¼æƒ…å ±ã‚’ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ä¿å­˜
        error_log_path = profile_session_dir / "error.log"
        with open(error_log_path, 'w') as f:
            f.write(f"Error occurred during profiled video generation\n")
            f.write(f"Session ID: {session_id}\n")
            f.write(f"Timestamp: {timestamp}\n")
            f.write(f"Error: {str(e)}\n")
            f.write("=" * 80 + "\n")
            f.write(error_trace)
        
        profiling_volume.commit()
        
        return {
            "status": "error",
            "session_id": session_id,
            "error": str(e),
            "traceback": error_trace,
            "profile_session_dir": str(profile_session_dir.relative_to(PROFILING_DIR))
        }

@app.function(
    image=ml_image,
    volumes={PROFILING_DIR: profiling_volume},
    timeout=600
)
def download_profiling_results(local_output_dir: str, session_id: Optional[str] = None):
    """
    Modal Volumeå†…ã®ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°çµæœã‚’ãƒ­ãƒ¼ã‚«ãƒ«ã«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã™ã‚‹é–¢æ•°
    """
    import shutil
    import tarfile
    from pathlib import Path
    
    print(f"ğŸ“¥ Downloading profiling results to: {local_output_dir}")
    
    if not PROFILING_DIR.exists():
        print("No profiling data found in Volume")
        return {"status": "no_data", "message": "No profiling data found"}
    
    # ãƒ­ãƒ¼ã‚«ãƒ«å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ
    local_path = Path(local_output_dir)
    local_path.mkdir(parents=True, exist_ok=True)
    
    downloaded_sessions = []
    
    if session_id:
        # ç‰¹å®šã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
        session_dirs = list(PROFILING_DIR.rglob(f"*{session_id}*"))
        if not session_dirs:
            return {"status": "not_found", "message": f"Session {session_id} not found"}
    else:
        # å…¨ã¦ã®ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°çµæœã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
        session_dirs = [d for d in PROFILING_DIR.rglob("*") if d.is_dir() and len(d.parts) == 3]  # function/session_dir level
    
    for session_dir in session_dirs:
        if session_dir.is_dir():
            session_name = session_dir.name
            local_session_dir = local_path / session_name
            
            print(f"ğŸ“ Downloading session: {session_name}")
            
            # ã‚»ãƒƒã‚·ãƒ§ãƒ³ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ãƒ­ãƒ¼ã‚«ãƒ«ã«ã‚³ãƒ”ãƒ¼
            shutil.copytree(session_dir, local_session_dir, dirs_exist_ok=True)
            
            # ã‚»ãƒƒã‚·ãƒ§ãƒ³æƒ…å ±ã‚’åé›†
            session_info = {
                "session_name": session_name,
                "local_path": str(local_session_dir),
                "file_count": len(list(local_session_dir.rglob("*"))),
                "size_mb": sum(f.stat().st_size for f in local_session_dir.rglob("*") if f.is_file()) / (1024 * 1024)
            }
            downloaded_sessions.append(session_info)
            
            print(f"âœ… Downloaded: {session_name} ({session_info['file_count']} files, {session_info['size_mb']:.1f} MB)")
    
    print(f"âœ… Download completed: {len(downloaded_sessions)} sessions")
    
    return {
        "status": "success",
        "local_output_dir": local_output_dir,
        "downloaded_sessions": downloaded_sessions,
        "total_sessions": len(downloaded_sessions)
    }

@app.function(
    image=ml_image,
    volumes={PROFILING_DIR: profiling_volume}
)
def list_profiling_sessions():
    """
    Modal Volumeå†…ã®ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°ã‚»ãƒƒã‚·ãƒ§ãƒ³ä¸€è¦§ã‚’è¡¨ç¤ºã™ã‚‹é–¢æ•°
    """
    import os
    from pathlib import Path
    from datetime import datetime
    
    print("ğŸ“Š Profiling Sessions in Modal Volume:")
    
    if not PROFILING_DIR.exists():
        print("No profiling data found")
        return {"status": "no_data", "sessions": []}
    
    sessions = []
    
    for root, dirs, files in os.walk(PROFILING_DIR):
        level = root.replace(str(PROFILING_DIR), '').count(os.sep)
        
        if level == 2:  # session level (function/label/session)
            session_path = Path(root)
            session_name = session_path.name
            function_name = session_path.parent.name
            
            # ã‚»ãƒƒã‚·ãƒ§ãƒ³æƒ…å ±ã‚’åé›†
            file_count = len([f for f in session_path.rglob("*") if f.is_file()])
            total_size = sum(f.stat().st_size for f in session_path.rglob("*") if f.is_file())
            size_mb = total_size / (1024 * 1024)
            
            # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‚’æŠ½å‡º
            timestamp_str = session_name.split('_')[0] if '_' in session_name else "unknown"
            
            session_info = {
                "session_name": session_name,
                "function_name": function_name,
                "timestamp": timestamp_str,
                "file_count": file_count,
                "size_mb": round(size_mb, 1),
                "path": str(session_path.relative_to(PROFILING_DIR))
            }
            sessions.append(session_info)
            
            print(f"  ğŸ“ {function_name}/{session_name}")
            print(f"     â° {timestamp_str}")
            print(f"     ğŸ“„ {file_count} files ({size_mb:.1f} MB)")
            print()
    
    # ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã§ã‚½ãƒ¼ãƒˆ
    sessions.sort(key=lambda x: x["timestamp"], reverse=True)
    
    print(f"Total sessions: {len(sessions)}")
    
    return {
        "status": "success",
        "sessions": sessions,
        "total_sessions": len(sessions)
    }

@app.function(
    image=ml_image,
    volumes={PROFILING_DIR: profiling_volume}
)
def clear_profiling_data(confirm: bool = False):
    """
    Modal Volumeå†…ã®ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¯ãƒªã‚¢ã™ã‚‹é–¢æ•°
    """
    import shutil
    
    if not confirm:
        return {
            "status": "confirmation_required",
            "message": "Set confirm=True to actually clear profiling data"
        }
    
    if PROFILING_DIR.exists():
        shutil.rmtree(PROFILING_DIR)
        PROFILING_DIR.mkdir(parents=True, exist_ok=True)
        profiling_volume.commit()
        print("ğŸ—‘ï¸  Profiling data cleared")
        return {"status": "cleared"}
    else:
        print("No profiling data to clear")
        return {"status": "no_data"}

@app.function(
    image=ml_image,
    gpu="H100",  # é«˜æ€§èƒ½GPU
    volumes={"/models": model_volume},
    timeout=3600,  # 1æ™‚é–“ã®ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ
    memory=32768,  # 32GB RAM
)
def generate_video_modal(
    image_bytes: bytes,
    image_filename: str,
    prompt: str = "rotating 360 degrees",
    video_size: tuple = (960, 544),
    fps: int = 30,
    infer_steps: int = 10,
    video_sections: int = 1,
    latent_window_size: int = 5,
    seed: int = 1234,
    save_path: str = "/tmp/output"
):
    """
    Modalä¸Šã§FramePackã«ã‚ˆã‚‹å‹•ç”»ç”Ÿæˆã‚’å®Ÿè¡Œã™ã‚‹é–¢æ•°
    """
    import sys
    import argparse
    from pathlib import Path
    
    # musubi_tunerãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‹ã‚‰fpack_generate_videoã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
    from musubi_tuner.fpack_generate_video import main, parse_args
    
    # ç”»åƒãƒã‚¤ãƒŠãƒªãƒ‡ãƒ¼ã‚¿ã‚’ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
    import os
    import tempfile
    
    # ä¸€æ™‚ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ç”»åƒã‚’ä¿å­˜
    temp_dir = "/tmp/modal_input"
    os.makedirs(temp_dir, exist_ok=True)
    
    temp_image_path = os.path.join(temp_dir, image_filename)
    with open(temp_image_path, 'wb') as f:
        f.write(image_bytes)
    
    print(f"ğŸ–¼ï¸  Saved input image to: {temp_image_path}")
    print(f"ğŸ“ Image size: {len(image_bytes)} bytes")
    
    # Makefileã®å¼•æ•°ã‚’å†ç¾ã—ã¦argparse.Namespaceã‚’æ§‹ç¯‰
    args = argparse.Namespace()
    
    # ãƒ¢ãƒ‡ãƒ«ãƒ‘ã‚¹ï¼ˆVolumeå†…ã®æ­£ã—ã„æ§‹é€ ã«åŸºã¥ãï¼‰
    args.dit = "/models/models/diffusion_models/FramePackI2V_HY"
    args.vae = "/models/models/vae/diffusion_pytorch_model.safetensors"
    args.text_encoder1 = "/models/models/text_encoder/model-00001-of-00004.safetensors"
    args.text_encoder2 = "/models/models/text_encoder_2/model.safetensors"
    args.image_encoder = "/models/models/image_encoder/model.safetensors"
    
    # å…¥åŠ›ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
    args.image_path = temp_image_path
    args.prompt = prompt
    args.video_size = list(video_size)
    args.fps = fps
    args.infer_steps = infer_steps
    args.video_sections = video_sections
    args.latent_window_size = latent_window_size
    args.seed = seed
    args.save_path = save_path
    
    # ãƒ‡ãƒã‚¤ã‚¹ãƒ»æœ€é©åŒ–è¨­å®š
    args.device = "cuda"
    args.attn_mode = "sdpa"
    args.fp8 = False
    args.fp8_llm = False
    args.fp8_scaled = True
    
    # VAEè¨­å®š
    args.vae_chunk_size = 32
    args.vae_spatial_tile_sample_min_size = 128
    
    # ãã®ä»–ã®è¨­å®š
    args.cache_dir = "/tmp/.cache/musubi_tuner"
    args.optimized_model_dir = "/models/models/diffusion_models/optimized"
    args.log_level = "DEBUG"
    args.profile = True
    
    # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤
    args.negative_prompt = None
    args.custom_system_prompt = None
    args.video_seconds = 5.0
    args.one_frame_inference = None
    args.control_image_path = None
    args.control_image_mask_path = None
    args.end_image_path = None
    args.latent_paddings = None
    args.f1 = False
    args.rope_scaling_factor = 0.5
    args.rope_scaling_timestep_threshold = None
    args.lora_weight = None
    args.lora_multiplier = 1.0
    args.include_patterns = None
    args.exclude_patterns = None
    args.save_merged_model = None
    args.lycoris = False
    args.blocks_to_swap = 0
    args.output_type = "video"
    args.no_metadata = False
    args.latent_path = None
    args.bulk_decode = False
    args.sample_solver = "unipc"
    args.embedded_cfg_scale = 10.0
    args.guidance_scale = 1.0
    args.guidance_rescale = 0.0
    
    # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ
    os.makedirs(save_path, exist_ok=True)
    
    # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ
    os.makedirs(args.cache_dir, exist_ok=True)
    
    print(f"ğŸ¬ Starting video generation on Modal...")
    print(f"Input image: {temp_image_path}")
    print(f"Prompt: {prompt}")
    print(f"Video size: {video_size}")
    print(f"Output path: {save_path}")
    
    try:
        # ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ©ãƒ¼ç”¨ã®è¨­å®š
        import torch
        import json
        from datetime import datetime
        import time
        
        timestamp = datetime.fromtimestamp(time.time()).strftime("%Y%m%d-%H%M%S")
        log_dir = f"{save_path}/profiles/{timestamp}"
        os.makedirs(log_dir, exist_ok=True)
        
        activities = [torch.profiler.ProfilerActivity.CPU, torch.profiler.ProfilerActivity.CUDA]
        
        with torch.profiler.profile(
            activities=activities,
            on_trace_ready=torch.profiler.tensorboard_trace_handler(log_dir),
            record_shapes=args.profile_shapes,
            profile_memory=args.profile_memory,
            with_stack=args.profile_stack
        ) as prof:
            prof.add_metadata_json("args", json.dumps(vars(args), default=str))
            
            # fpack_generate_video.pyã‹ã‚‰å¿…è¦ãªé–¢æ•°ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
            from musubi_tuner.fpack_generate_video import get_generation_settings, generate, save_output
            
            # ç”Ÿæˆè¨­å®šã‚’å–å¾—
            gen_settings = get_generation_settings(args)
            
            # å‹•ç”»ç”Ÿæˆã‚’å®Ÿè¡Œ
            result = generate(args, gen_settings, prof=prof)
            
            if result is None:
                # Model was saved, no further processing needed
                return {
                    "status": "success", 
                    "message": "Model saved successfully, no video generation performed",
                    "output_path": save_path,
                    "files": [],
                    "result_files": {},
                    "log_dir": log_dir
                }
            
            vae, latent = result
            
            # çµæœã‚’ä¿å­˜
            save_output(args, vae, latent[0], gen_settings.device, None)
        
        print(f"âœ… Video generation completed successfully!")
        print(f"Output saved to: {save_path}")
        
        # ç”Ÿæˆã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç¢ºèªã—ã¦ãƒã‚¤ãƒŠãƒªãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦è¿”ã™
        output_files = list(Path(save_path).glob("*.mp4"))
        result_files = {}
        
        for file_path in output_files:
            if file_path.is_file():
                with open(file_path, 'rb') as f:
                    file_data = f.read()
                result_files[file_path.name] = file_data
                print(f"ğŸ“„ Captured output file: {file_path.name} ({len(file_data)} bytes)")
        
        # log_dirã¯æ—¢ã«ä¸Šã§å®šç¾©æ¸ˆã¿
        
        return {
            "status": "success",
            "output_path": save_path,
            "files": [str(f) for f in output_files],
            "result_files": result_files,  # ãƒã‚¤ãƒŠãƒªãƒ‡ãƒ¼ã‚¿ã‚’å«ã‚€
            "log_dir": log_dir
        }
        
    except Exception as e:
        print(f"âŒ Error during video generation: {str(e)}")
        import traceback
        traceback.print_exc()
        return {
            "status": "error",
            "error": str(e),
            "traceback": traceback.format_exc()
        }

@app.function(
    image=ml_image,
    volumes={"/models": model_volume},
    timeout=3600
)
def upload_models_from_local(local_model_dir: str):
    """
    ãƒ­ãƒ¼ã‚«ãƒ«ã®ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’Modal Volumeã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã™ã‚‹é–¢æ•°
    """
    import shutil
    from pathlib import Path
    
    local_path = Path(local_model_dir)
    if not local_path.exists():
        raise ValueError(f"Local model directory does not exist: {local_model_dir}")
    
    print(f"ğŸ“¦ Uploading models from {local_model_dir} to Modal Volume...")
    
    # ãƒ¢ãƒ‡ãƒ«ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®æ§‹é€ ã‚’å†ç¾
    model_dirs = [
        "diffusion_models/FramePackI2V_HY",
        "vae",
        "text_encoder", 
        "text_encoder_2",
        "image_encoder",
        "diffusion_models/optimized"
    ]
    
    for model_dir in model_dirs:
        local_model_path = local_path / model_dir
        remote_model_path = Path("/models") / model_dir
        
        if local_model_path.exists():
            print(f"Copying {model_dir}...")
            remote_model_path.parent.mkdir(parents=True, exist_ok=True)
            if local_model_path.is_dir():
                shutil.copytree(local_model_path, remote_model_path, dirs_exist_ok=True)
            else:
                shutil.copy2(local_model_path, remote_model_path)
        else:
            print(f"âš ï¸  Warning: {model_dir} not found in local directory")
    
    model_volume.commit()
    print("âœ… Model upload completed!")

@app.function(
    image=ml_image,
    volumes={"/models": model_volume},
    timeout=1800
)  
def download_models_from_hf():
    """
    Hugging Face Hubã‹ã‚‰ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã™ã‚‹é–¢æ•°
    """
    from huggingface_hub import snapshot_download
    import os
    
    print("ğŸ“¦ Downloading models from Hugging Face Hub...")
    
    # ç’°å¢ƒå¤‰æ•°ã‹ã‚‰HFãƒˆãƒ¼ã‚¯ãƒ³ã‚’å–å¾—ï¼ˆå¿…è¦ã«å¿œã˜ã¦ï¼‰
    hf_token = os.getenv("HF_TOKEN")
    
    try:
        # FramePack I2V ãƒ¢ãƒ‡ãƒ«ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ä¾‹
        # å®Ÿéš›ã®ãƒªãƒã‚¸ãƒˆãƒªåã¯é©åˆ‡ãªã‚‚ã®ã«å¤‰æ›´ã—ã¦ãã ã•ã„
        model_repo = "your-org/framepack-i2v-model"  # å®Ÿéš›ã®ãƒªãƒã‚¸ãƒˆãƒªåã«å¤‰æ›´
        
        snapshot_download(
            repo_id=model_repo,
            local_dir="/models/diffusion_models/FramePackI2V_HY",
            token=hf_token,
            ignore_patterns=["*.git*", "README.md", "*.md"]
        )
        
        model_volume.commit()
        print("âœ… Models downloaded successfully!")
        
    except Exception as e:
        print(f"âŒ Error downloading models: {str(e)}")
        print("Please ensure you have the correct repository access and HF_TOKEN is set")

@app.function(
    image=ml_image,
    volumes={"/models": model_volume}
)
def list_models():
    """
    Modal Volumeå†…ã®ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒªã‚¹ãƒˆã‚¢ãƒƒãƒ—ã™ã‚‹é–¢æ•°
    """
    import os
    from pathlib import Path
    
    print("ğŸ“‹ Models in Modal Volume:")
    model_root = Path("/models")
    
    if not model_root.exists():
        print("No models directory found")
        return
    
    for root, dirs, files in os.walk(model_root):
        level = root.replace(str(model_root), '').count(os.sep)
        indent = ' ' * 2 * level
        print(f"{indent}{os.path.basename(root)}/")
        subindent = ' ' * 2 * (level + 1)
        for file in files:
            file_path = Path(root) / file
            file_size = file_path.stat().st_size if file_path.exists() else 0
            size_mb = file_size / (1024 * 1024)
            print(f"{subindent}{file} ({size_mb:.1f} MB)")

@app.function(image=ml_image)
def test_modal_setup():
    """
    Modalç’°å¢ƒã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã‚’ãƒ†ã‚¹ãƒˆã™ã‚‹é–¢æ•°
    """
    print("ğŸ§ª Testing Modal setup...")
    
    # CUDA availability check
    try:
        import torch
        print(f"âœ… PyTorch version: {torch.__version__}")
        print(f"âœ… CUDA available: {torch.cuda.is_available()}")
        if torch.cuda.is_available():
            print(f"âœ… CUDA device count: {torch.cuda.device_count()}")
            print(f"âœ… CUDA device name: {torch.cuda.get_device_name(0)}")
    except Exception as e:
        print(f"âŒ PyTorch/CUDA test failed: {e}")
    
    # Other dependencies check
    dependencies = ["transformers", "diffusers", "safetensors", "accelerate", "diskcache"]
    for dep in dependencies:
        try:
            __import__(dep)
            print(f"âœ… {dep} imported successfully")
        except ImportError:
            print(f"âŒ {dep} import failed")
    
    print("ğŸ‰ Modal setup test completed!")

@app.local_entrypoint()
def main(
    image_path: str = "path/to/your/image.jpg",
    prompt: str = "rotating 360 degrees",
    video_width: int = 960,
    video_height: int = 544,
    fps: int = 30,
    infer_steps: int = 10,
    video_sections: int = 1,
    latent_window_size: int = 5,
    seed: int = 1234,
    save_path: str = "/tmp/modal_output",
    # ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°è¨­å®š
    enable_profiling: bool = True,
    profile_steps: int = 3,
    profile_label: Optional[str] = None,
    record_shapes: bool = False,
    profile_memory: bool = True,
    with_stack: bool = True,
    print_profile_summary: int = 10,
    download_profiles: bool = True,
    local_profile_dir: str = "./profiling_results"
):
    """
    Modalä¸Šã§ã®å‹•ç”»ç”Ÿæˆã‚’å®Ÿè¡Œã™ã‚‹ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆï¼ˆãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°å¯¾å¿œï¼‰
    
    ä½¿ç”¨ä¾‹:
    modal run src/musubi_tuner/fpack_generate_video_on_modal.py \
        --image-path "path/to/image.jpg" \
        --prompt "rotating 360 degrees" \
        --enable-profiling \
        --profile-steps 3 \
        --record-shapes \
        --download-profiles
    """
    import os
    from pathlib import Path
    
    print(f"ğŸš€ Starting Modal video generation with profiling...")
    print(f"ğŸ“¸ Loading image from: {image_path}")
    
    # å…¥åŠ›ç”»åƒã‚’ãƒã‚¤ãƒŠãƒªã¨ã—ã¦èª­ã¿è¾¼ã¿
    if not os.path.exists(image_path):
        raise FileNotFoundError(f"Input image not found: {image_path}")
    
    with open(image_path, 'rb') as f:
        image_bytes = f.read()
    
    image_filename = Path(image_path).name
    print(f"ğŸ“ Image loaded: {image_filename} ({len(image_bytes)} bytes)")
    
    # ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°ãŒæœ‰åŠ¹ãªå ´åˆã¯ profile_video_generation ã‚’ä½¿ç”¨
    if enable_profiling:
        print(f"ğŸ” Running with profiling enabled...")
        result = profile_video_generation.remote(
            image_bytes=image_bytes,
            image_filename=image_filename,
            prompt=prompt,
            video_size=(video_width, video_height),
            fps=fps,
            infer_steps=infer_steps,
            video_sections=video_sections,
            latent_window_size=latent_window_size,
            seed=seed,
            save_path="/tmp/output",  # Modalå†…ã®ä¸€æ™‚ãƒ‘ã‚¹
            profile_steps=profile_steps,
            profile_label=profile_label,
            record_shapes=record_shapes,
            profile_memory=profile_memory,
            with_stack=with_stack,
            print_profile_summary=print_profile_summary
        )
    else:
        print(f"ğŸ¬ Running without profiling...")
        result = generate_video_modal.remote(
            image_bytes=image_bytes,
            image_filename=image_filename,
            prompt=prompt,
            video_size=(video_width, video_height),
            fps=fps,
            infer_steps=infer_steps,
            video_sections=video_sections,
            latent_window_size=latent_window_size,
            seed=seed,
            save_path="/tmp/output"  # Modalå†…ã®ä¸€æ™‚ãƒ‘ã‚¹
        )
    
    print(f"ğŸ“Š Generation result status: {result.get('status', 'unknown')}")
    
    if result.get("status") == "success":
        # ãƒ­ãƒ¼ã‚«ãƒ«ä¿å­˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ
        os.makedirs(save_path, exist_ok=True)
        
        # ç”Ÿæˆã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ­ãƒ¼ã‚«ãƒ«ã«ä¿å­˜
        if result.get("result_files"):
            for filename, file_data in result["result_files"].items():
                local_file_path = os.path.join(save_path, filename)
                with open(local_file_path, 'wb') as f:
                    f.write(file_data)
                
                print(f"ğŸ’¾ Saved to local: {local_file_path} ({len(file_data)} bytes)")
        
        # ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°çµæœã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
        if enable_profiling and download_profiles and result.get("session_id"):
            print(f"ğŸ“¥ Downloading profiling results...")
            profile_result = download_profiling_results.remote(
                local_output_dir=local_profile_dir,
                session_id=result["session_id"]
            )
            
            if profile_result.get("status") == "success":
                print(f"âœ… Profiling results downloaded to: {local_profile_dir}")
                for session in profile_result["downloaded_sessions"]:
                    print(f"   ğŸ“ {session['session_name']}: {session['file_count']} files ({session['size_mb']:.1f} MB)")
            else:
                print(f"âš ï¸  Failed to download profiling results: {profile_result}")
        
        print(f"âœ… Video generation completed! Check output in: {save_path}")
        
        # ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°æƒ…å ±ã®è¡¨ç¤º
        if enable_profiling and result.get("timing_log"):
            print(f"\nâ±ï¸  Timing Log:")
            print(result["timing_log"])
            
    elif result.get("status") == "error":
        print(f"âŒ Error occurred: {result.get('error', 'Unknown error')}")
        if result.get("traceback"):
            print(f"Traceback:\n{result['traceback']}")
    else:
        print(f"âš ï¸  Unexpected result: {result}")
    
    return result

if __name__ == "__main__":
    # CLIã§ã®å®Ÿè¡Œã‚’ã‚µãƒãƒ¼ãƒˆ
    import sys
    if len(sys.argv) > 1:
        # ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°ãŒã‚ã‚‹å ´åˆã¯ã€mainé–¢æ•°ã‚’ç›´æ¥å‘¼ã³å‡ºã—
        main()
    else:
        print("Usage: modal run src/musubi_tuner/fpack_generate_video_on_modal.py --image-path <path>")




